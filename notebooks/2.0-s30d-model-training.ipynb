{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c9d9d89-4af7-4dc8-b1f3-c77dddad0c36",
   "metadata": {},
   "source": [
    "# Model training and prediction - `s30d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f08843e3-1ca8-42ec-a344-1c5f560441dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4918d091-6dc7-47e1-8419-8973ebbf246c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ludvigwarnberggerdin/projects/ttris/pemett'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66d758ca-f517-4df4-8bc0-f1cbc91226ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb6ed398-04d7-4bba-8693-e79e973e5487",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"./data/processed/s30d/X_train.csv\", index_col = 0)\n",
    "y_train = pd.read_csv(\"./data/processed/s30d/y_train.csv\", index_col = 0).s30d\n",
    "X_test = pd.read_csv(\"./data/processed/s30d/X_test.csv\", index_col = 0)\n",
    "y_test = pd.read_csv(\"./data/processed/s30d/y_test.csv\", index_col = 0).s30d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb610948-9c80-4507-861c-feeb3318fbb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    94.197074\n",
       "1.0     5.802926\n",
       "Name: s30d, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts() / len(y_train.index) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe14dc61-2fe7-4188-9b39-5c4abb2f149d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_features = [\"age\", \"hr\", \"sbp\", \"dbp\", \"spo2\", \"rr\", \"delay\"]\n",
    "cat_features = list(X_train.loc[:, ~X_train.columns.isin(cont_features)].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00463518-a24f-466b-93db-529f65cf8a96",
   "metadata": {},
   "source": [
    "### Lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "084141d7-22d5-435b-b284-8e8eb769ced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b17e6786-1b75-4f11-a8d8-05cbe6d3e68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "continous_transformer = StandardScaler()\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cont', continous_transformer, cont_features)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdb528c2-95b8-4505-801c-9fddf7a94935",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train.loc[:, cont_features] = ss.fit_transform(X_train.loc[:, cont_features])\n",
    "X_test.loc[:, cont_features] = ss.fit_transform(X_test.loc[:, cont_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db9aca14-cc6c-49eb-8d39-6604121d1c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc7a154a-48d9-4936-bf5a-b6695a639991",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ludvigwarnberggerdin/miniforge3/envs/pemett/lib/python3.10/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    categorical_feature = cat_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc1c960e-bbf2-4279-853c-f3d4207a7ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob_train = clf.predict_proba(X = X_train)\n",
    "y_pred_prob_test = clf.predict_proba(X = X_test)\n",
    "y_pred_train = clf.predict(X = X_train)\n",
    "y_pred_test = clf.predict(X = X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ee16dc-8458-444d-b014-bc6852a5dfcd",
   "metadata": {},
   "source": [
    "Report for continous scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c592bf4a-44bf-40c5-a850-662b79c29caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      5860\n",
      "         1.0       1.00      0.99      1.00       361\n",
      "\n",
      "    accuracy                           1.00      6221\n",
      "   macro avg       1.00      1.00      1.00      6221\n",
      "weighted avg       1.00      1.00      1.00      6221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true = y_train, y_pred = y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "740c9e4e-0d5f-416e-9fb9-0a947c589c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.98      1954\n",
      "         1.0       0.77      0.62      0.69       120\n",
      "\n",
      "    accuracy                           0.97      2074\n",
      "   macro avg       0.87      0.80      0.83      2074\n",
      "weighted avg       0.96      0.97      0.97      2074\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true = y_test, y_pred = y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205b5800-760b-4d9b-8b96-c7ea65b7d47a",
   "metadata": {},
   "source": [
    "Gridsearch breaks for the continous score (to enable comparison with clinicians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7e57514-909f-4bdb-83e4-6f83e4e7e423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "from src.models.train_model import generate_all_combinations\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from typing import Callable, Optional\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d5af0873-c6fb-4b4d-9714-987c8bb04315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_inner_loop(base_clfs: list,\n",
    "                  inner_loop: Callable, \n",
    "                  X: pd.DataFrame, \n",
    "                  y: pd.Series,\n",
    "                  verbose: bool) -> np.ndarray:\n",
    "    \"\"\"Run inner loop of k-fold cross-validation.\n",
    "    \n",
    "    Uses sklearn's cross_val_predict.\n",
    "    \n",
    "    That is,\n",
    "    1. Fit classifier to the training folds.\n",
    "    2. Make prediction on the validation fold.\n",
    "    3. Use all folds as validation fold, one time each.\n",
    "\n",
    "    Args:\n",
    "      base_clfs: List of classifiers. E.g. [LGBMClassifier, LogisticRegression]\n",
    "      inner_loop: scikit-learn callable to split into folds\n",
    "      X: Features\n",
    "      y: Targets\n",
    "\n",
    "    Returns:\n",
    "      Each column represent predictions by each respective classifier\n",
    "    \"\"\"\n",
    "    predictions = np.zeros((len(X_train.index), ))\n",
    "    for clf in base_clfs:\n",
    "        if verbose: print(\"Running predictions for \" + str(clf))\n",
    "        preds = cross_val_predict(\n",
    "            estimator=clf,\n",
    "            X=X,\n",
    "            y=y,\n",
    "            cv=inner_loop\n",
    "        )\n",
    "        if predictions.any():\n",
    "            predictions = np.hstack([predictions, preds[:, np.newaxis]])\n",
    "        else:\n",
    "            predictions = preds[:, np.newaxis]\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "104baafa-9465-4074-b79c-a6f2c44b8906",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "\n",
    "def cv_outer_loop(base_clfs: list, meta_clf: Callable,\n",
    "                  all_hyper_parameters: list,\n",
    "                  X: pd.DataFrame, y: pd.Series,\n",
    "                  use_meta_features: bool = False, \n",
    "                  verbose: bool = False, refit: bool = False,\n",
    "                  **kwargs):\n",
    "    \"\"\"Run outer cross-validation.\n",
    "    \n",
    "    That is, find the best combination cut-points for the classifier.\n",
    "    \"Best\" is defined by the highest AUC of ROC.\n",
    "    \n",
    "    Inspired by:\n",
    "        https://github.com/rasbt/mlxtend/blob/master/mlxtend/classifier/stacking_cv_classification.py\n",
    "        \n",
    "    Args:\n",
    "        base_clfs: Base classifiers\n",
    "        meta_clf: Meta classifier\n",
    "        all_hyper_parameters: Model hyper parameters and breaks for continous probabilities\n",
    "        X: Features\n",
    "        y: Targets\n",
    "        use_meta_features: If True, the feature set for meta classifier is predicted probabilities\n",
    "                           of positive labels from base classifiers + features used to train\n",
    "                           base classifiers\n",
    "        verbose: If True, logging is used\n",
    "\n",
    "    Returns:\n",
    "        Hyper parameters yielding highest average auc of roc across outer folds\n",
    "    \"\"\"\n",
    "    \n",
    "    def fit(**kwargs):\n",
    "        base_clfs_ = []\n",
    "        # Set the hyper hyper parameters of the base classifiers\n",
    "        for clfk in base_clfs.keys():\n",
    "            ks = [s for s in hyper_parameters.keys() if clfk in s]\n",
    "            clf_params = {k.split(\"__\")[1]: hyper_parameters.get(k) for k in ks}\n",
    "            clf = base_clfs[clfk]\n",
    "            clf.set_params(**clf_params)\n",
    "            base_clfs_.append(clf)\n",
    "        \n",
    "        # Get meta features of training set\n",
    "        meta_features_train = cv_inner_loop(\n",
    "            base_clfs=base_clfs_,\n",
    "            inner_loop=inner_loop,\n",
    "            X=X_train,\n",
    "            y=y_train,\n",
    "            verbose=verbose\n",
    "        )\n",
    "\n",
    "        # Fit meta classifier to meta features of train\n",
    "        meta_clf.fit(meta_features_train, y_train)\n",
    "        \n",
    "        return base_clfs_, meta_clf, meta_features_train\n",
    "        \n",
    "    def predict_and_score(**kwargs):\n",
    "        \n",
    "        base_clfs_, meta_clf, meta_features_train = fit(\n",
    "            base_clfs=base_clfs,\n",
    "            meta_clf=meta_clf,\n",
    "            hyper_parameters=hyper_parameters,\n",
    "            X_train=X_train,\n",
    "            y_train=y_train,\n",
    "            verbose=verbose\n",
    "        )\n",
    "\n",
    "        # Get meta features of validation set\n",
    "        per_model_preds = []\n",
    "        for clf in base_clfs_:\n",
    "            clf.fit(X_train, y_train)\n",
    "            prediction = clf.predict_proba(X_val)[:, :-1]\n",
    "            per_model_preds.append(prediction)\n",
    "        meta_features_val = np.hstack(per_model_preds)\n",
    "        \n",
    "        # Fit meta classifier to meta features of train\n",
    "        meta_clf.fit(meta_features_train, y_train)\n",
    "        # Predict using validation meta features\n",
    "        y_pred_prob_meta = meta_clf.predict_proba(meta_features_val)\n",
    "        # Calculate AUC of ROC for cut predictions\n",
    "        binned_predictions = pd.cut(\n",
    "            x=y_pred_prob_meta[:, 1],\n",
    "            bins=hyper_parameters[\"breaks\"],\n",
    "            labels=[0, 1, 2, 3],\n",
    "            right=True,\n",
    "            include_lowest=False\n",
    "        )\n",
    "        return roc_auc_score(\n",
    "            y_true=y_val,\n",
    "            y_score=binned_predictions\n",
    "        )\n",
    "                \n",
    "    ## Setup splitting\n",
    "    inner_folds = 3\n",
    "    outer_folds = 2\n",
    "    inner_loop = StratifiedKFold(n_splits = inner_folds)\n",
    "    outer_loop = StratifiedKFold(n_splits = outer_folds)\n",
    "    \n",
    "    ## Setup for recording auc from each combination of hps\n",
    "    roc_aucs = pd.DataFrame(\n",
    "        data = np.zeros((len(all_hyper_parameters), outer_folds)),\n",
    "        columns = range(1, outer_folds + 1)\n",
    "    )\n",
    "    \n",
    "    for i, hyper_parameters in enumerate(all_hyper_parameters):\n",
    "\n",
    "        for j, (train_index, val_index) in enumerate(outer_loop.split(X, y)):\n",
    "        \n",
    "            X_train = X.iloc[train_index]\n",
    "            y_train = y.iloc[train_index]\n",
    "            X_val = X.iloc[val_index]\n",
    "            y_val = y.iloc[val_index]\n",
    "            \n",
    "            auc = predict_and_score(\n",
    "                base_clfs=base_clfs,\n",
    "                meta_clf=meta_clf,\n",
    "                hyper_parameters=hyper_parameters,\n",
    "                inner_loop=inner_loop,\n",
    "                X_train=X_train,\n",
    "                y_train=y_train,\n",
    "                X_val=X_val,\n",
    "                y_val=y_val,\n",
    "                verbose=verbose\n",
    "            )\n",
    "            \n",
    "            roc_aucs.iloc[i, j] = 1 - auc\n",
    "    \n",
    "    max_row = roc_aucs.mean(axis=1).idxmax()\n",
    "    best_hyper_parameters = all_hyper_parameters[max_row]\n",
    "    \n",
    "    if refit: \n",
    "        base_clfs_, meta_clf, _ = fit(\n",
    "            base_clfs=base_clfs,\n",
    "            meta_clf=meta_clf,\n",
    "            hyper_parameters=hyper_parameters,\n",
    "            X_train=X_train,\n",
    "            y_train=y_train,\n",
    "            verbose=verbose\n",
    "        )\n",
    "    \n",
    "    return base_clfs_, meta_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "5ee3654e-7a80-4e7d-be40-7dfec004e221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "all_breaks = [(0, ) + x + (np.inf,) for x in it.combinations(np.arange(0.01, 1, 0.01), r=3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "8bff7851-5b1f-4d4c-b729-272b7c698886",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_parameters = {\n",
    "    \"lgbm1__max_depth\": [100, 500],\n",
    "    \"lgbm1__num_leaves\": [200, 100],\n",
    "    \"lgbm2__max_depth\": [100, 200],\n",
    "    \"breaks\": all_breaks[:1]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "27ae05c0-1ad4-4b86-8a15-b78d89c21982",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_clfs = {\n",
    "    \"lgbm1\": LGBMClassifier(),\n",
    "    \"lgbm2\": LGBMClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "8e3662ba-f282-4633-af9a-9352ec551ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hyper_parameters = generate_all_combinations(hyper_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "1d1a2ca9-96d1-4f79-b38c-e7448d06a6a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'meta_clf' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4r/pj221_cx4fsc736mmyv_9lnr0000gn/T/ipykernel_4901/3606022874.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m best_hyper_parameters = cv_outer_loop(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mbase_clfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_clfs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmeta_clf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mall_hyper_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_hyper_parameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mall_breaks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_breaks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/4r/pj221_cx4fsc736mmyv_9lnr0000gn/T/ipykernel_4901/908103356.py\u001b[0m in \u001b[0;36mcv_outer_loop\u001b[0;34m(base_clfs, meta_clf, all_hyper_parameters, X, y, use_meta_features, verbose, refit, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0my_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             auc = predict_and_score(\n\u001b[0m\u001b[1;32m    114\u001b[0m                 \u001b[0mbase_clfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_clfs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0mmeta_clf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta_clf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/4r/pj221_cx4fsc736mmyv_9lnr0000gn/T/ipykernel_4901/908103356.py\u001b[0m in \u001b[0;36mpredict_and_score\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     58\u001b[0m         base_clfs_, meta_clf, meta_features_train = fit(\n\u001b[1;32m     59\u001b[0m             \u001b[0mbase_clfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_clfs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 60\u001b[0;31m             \u001b[0mmeta_clf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmeta_clf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     61\u001b[0m             \u001b[0mhyper_parameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhyper_parameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'meta_clf' referenced before assignment"
     ]
    }
   ],
   "source": [
    "best_hyper_parameters = cv_outer_loop(\n",
    "    base_clfs=base_clfs,\n",
    "    meta_clf=LogisticRegression(),\n",
    "    all_hyper_parameters=all_hyper_parameters,\n",
    "    all_breaks=all_breaks,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    "    refit=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f106e1-9787-497e-8a9b-e782ca0a8c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyper_parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f42dcbb5-dc26-4e97-b9ca-4de29cb22132",
   "metadata": {},
   "source": [
    "Refit each classifier to the training set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
