{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c9d9d89-4af7-4dc8-b1f3-c77dddad0c36",
   "metadata": {},
   "source": [
    "# Model training and prediction - `s30d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f08843e3-1ca8-42ec-a344-1c5f560441dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4918d091-6dc7-47e1-8419-8973ebbf246c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ludvigwarnberggerdin/projects/ttris/pemett'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66d758ca-f517-4df4-8bc0-f1cbc91226ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb6ed398-04d7-4bba-8693-e79e973e5487",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"./data/processed/s30d/X_train.csv\", index_col = 0)\n",
    "y_train = pd.read_csv(\"./data/processed/s30d/y_train.csv\", index_col = 0).s30d\n",
    "X_test = pd.read_csv(\"./data/processed/s30d/X_test.csv\", index_col = 0)\n",
    "y_test = pd.read_csv(\"./data/processed/s30d/y_test.csv\", index_col = 0).s30d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb610948-9c80-4507-861c-feeb3318fbb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    94.197074\n",
       "1.0     5.802926\n",
       "Name: s30d, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts() / len(y_train.index) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe14dc61-2fe7-4188-9b39-5c4abb2f149d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_features = [\"age\", \"hr\", \"sbp\", \"dbp\", \"spo2\", \"rr\", \"delay\"]\n",
    "cat_features = list(X_train.loc[:, ~X_train.columns.isin(cont_features)].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00463518-a24f-466b-93db-529f65cf8a96",
   "metadata": {},
   "source": [
    "### Lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "084141d7-22d5-435b-b284-8e8eb769ced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b17e6786-1b75-4f11-a8d8-05cbe6d3e68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "continous_transformer = StandardScaler()\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cont', continous_transformer, cont_features)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdb528c2-95b8-4505-801c-9fddf7a94935",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train.loc[:, cont_features] = ss.fit_transform(X_train.loc[:, cont_features])\n",
    "X_test.loc[:, cont_features] = ss.fit_transform(X_test.loc[:, cont_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db9aca14-cc6c-49eb-8d39-6604121d1c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc7a154a-48d9-4936-bf5a-b6695a639991",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ludvigwarnberggerdin/miniforge3/envs/pemett/lib/python3.10/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    categorical_feature = cat_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc1c960e-bbf2-4279-853c-f3d4207a7ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob_train = clf.predict_proba(X = X_train)\n",
    "y_pred_prob_test = clf.predict_proba(X = X_test)\n",
    "y_pred_train = clf.predict(X = X_train)\n",
    "y_pred_test = clf.predict(X = X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ee16dc-8458-444d-b014-bc6852a5dfcd",
   "metadata": {},
   "source": [
    "Report for continous scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c592bf4a-44bf-40c5-a850-662b79c29caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      5860\n",
      "         1.0       1.00      0.99      1.00       361\n",
      "\n",
      "    accuracy                           1.00      6221\n",
      "   macro avg       1.00      1.00      1.00      6221\n",
      "weighted avg       1.00      1.00      1.00      6221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true = y_train, y_pred = y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "740c9e4e-0d5f-416e-9fb9-0a947c589c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.98      1954\n",
      "         1.0       0.77      0.62      0.69       120\n",
      "\n",
      "    accuracy                           0.97      2074\n",
      "   macro avg       0.87      0.80      0.83      2074\n",
      "weighted avg       0.96      0.97      0.97      2074\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true = y_test, y_pred = y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205b5800-760b-4d9b-8b96-c7ea65b7d47a",
   "metadata": {},
   "source": [
    "Gridsearch breaks for the continous score (to enable comparison with clinicians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ad8809c8-cbe9-400f-90ce-6ebfb1a88f6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2948371950.py, line 28)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/4r/pj221_cx4fsc736mmyv_9lnr0000gn/T/ipykernel_1417/2948371950.py\"\u001b[0;36m, line \u001b[0;32m28\u001b[0m\n\u001b[0;31m    preds =\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "import random\n",
    "from src.models.train_model import generate_all_combinations\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from typing import Callable, Optional\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold\n",
    "\n",
    "def cv_inner_loop(base_clfs: list, hyper_parameters: list, \n",
    "                  inner_loop: Callable, X: pd.DataFrame, \n",
    "                  y: pd.Series) -> pd.DataFrame:\n",
    "    \"\"\"Run inner loop of k-fold cross-validation.\n",
    "    \n",
    "    Uses sklearn's cross_val_predict\n",
    "    \n",
    "    That is,\n",
    "    1. Fit classifier to the training folds.\n",
    "    2. Make prediction on the validation fold.\n",
    "    3. Repeat for all k-folds.\n",
    "\n",
    "    Args:\n",
    "      clf: Classifier \n",
    "      hyper_parameters: \n",
    "\n",
    "    Returns:\n",
    "      Predictions\n",
    "    \"\"\"\n",
    "    for clflk in base_clfs.keys()\n",
    "        d = clfs[clfk]\n",
    "        clf = d['clf']\n",
    "        hp = d['hp']\n",
    "        clf = clf.set_params(**hp)\n",
    "        print(\"Running predictions for \" + str(clf))\n",
    "        preds = cross_val_predict(\n",
    "            estimator=clf,\n",
    "            X=X,\n",
    "            y=y,\n",
    "            cv=inner_loop\n",
    "        )\n",
    "        if predictions.any():\n",
    "            predictions = np.hstack([predictions, preds[:, np.newaxis]])\n",
    "        else:\n",
    "            predictions = preds[:, np.newaxis]\n",
    "            \n",
    "    preds = np.zeros((len(X_train.index), ))\n",
    "    for i, (train_index, val_index) in enumerate(inner_loop.split(X_train, y_train)):\n",
    "\n",
    "        X_train_ = X_train.iloc[train_index]\n",
    "        y_train_ = y_train.iloc[train_index]\n",
    "\n",
    "        X_val = X_train.iloc[val_index]\n",
    "        y_val = y_train.iloc[val_index]\n",
    "\n",
    "        for j, hp in enumerate(tqdm(hyper_parameters)):\n",
    "\n",
    "            clf = clf.set_params(**hp)\n",
    "            clf.fit(X_train_, y_train_)\n",
    "\n",
    "            y_pred_val = clf.predict(X_val)\n",
    "            y_pred_prob_val = clf.predict_proba(X_val)\n",
    "            preds[val_index] = y_pred_prob_val[:, 1]\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "39e77566-7219-4f00-8a2a-5a4a20be9d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_outer_loop(base_clfs: list, meta_clf: Callable,\n",
    "                  X_train: pd.DataFrame, y_train: pd.Series,\n",
    "                  use_meta_features: bool = False, \n",
    "                  **kwargs):\n",
    "    \"\"\"Conduct outer cross-validation.\n",
    "    \n",
    "    That is, find the best combination cut-points for the classifier.\n",
    "    \n",
    "    Inspired by:\n",
    "        https://github.com/rasbt/mlxtend/blob/master/mlxtend/classifier/stacking_cv_classification.py\n",
    "        \n",
    "    Args:\n",
    "        base_clfs: Base classifiers.\n",
    "        meta_clf:\n",
    "        X_train:\n",
    "        y_train\n",
    "        use_meta_features\n",
    "    \"\"\"\n",
    "    ## Fit each classifier to the original training set\n",
    "    meta_predictions = np.array([])\n",
    "    clf_keys = base_clfs.keys()\n",
    "    ## Setup splitting\n",
    "    inner_folds = 5\n",
    "    outer_folds = 2\n",
    "    inner_loop = StratifiedKFold(n_splits = inner_folds)\n",
    "    outer_loop = StratifiedKFold(n_splits = outer_folds)\n",
    "    \n",
    "    ## Setup for recording auc from each combination of hps\n",
    "    roc_aucs = pd.DataFrame(\n",
    "        data = np.zeros((len(hyper_parameters), n_folds)),\n",
    "        columns = range(1, n_folds + 1),\n",
    "        index = [str(hp) for hp in hyper_parameters]\n",
    "    )\n",
    "\n",
    "    for i, (train_index, val_index) in enumerate(outer_loop.split(X_train, y_train)):\n",
    "        \n",
    "        X_train_ = X_train.iloc[train_index]\n",
    "        y_train_ = y_train.iloc[train_index]\n",
    "\n",
    "        X_val = X_train.iloc[val_index]\n",
    "        y_val = y_train.iloc[val_index]\n",
    "        \n",
    "        for j, hp in enumerate(hyper_parameters):\n",
    "            \n",
    "            hp = \n",
    "            breaks = hp['breaks']\n",
    "            \n",
    "            ## Fit each classifier to the predicted probabilities\n",
    "            base_predictions = inner_loop(\n",
    "                base_clfs=base_clfs\n",
    "                hyper_parameters=hyper_parameters,\n",
    "                inner_loop=inner_loop,\n",
    "                X=X_train_,\n",
    "                y=y_train_\n",
    "            )\n",
    "    \n",
    "            ## Fit the meta clf to predictions, and predict on validation set\n",
    "            meta_clf.fit(predictions, y_train)\n",
    "            y_pred_prob_meta = meta_clf.predict_proba(predictions)\n",
    "            binned_predictions = pd.cut(y_pred_prob_val[:, 1], breaks, labels = [0, 1, 2, 3], right = True, include_lowest = False)\n",
    "            roc_aucs.iloc[j, i] = roc_auc_score(y_true = y_val, y_score = binned_predictions)\n",
    "    \n",
    "    return base_clfs, meta_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f008eef4-35ed-4718-b60c-bff6727a6865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "19f4161c-d968-469d-b640-2d16cc0671d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "all_breaks = [(0, ) + x + (np.inf,) for x in it.combinations(np.arange(0.01, 1, 0.01), r=3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "263a6b02-bc27-4de9-8177-c15b856ecf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_parameters = {'max_depth': [5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "1d1a2ca9-96d1-4f79-b38c-e7448d06a6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "lightgbm.sklearn.LGBMModel.set_params() argument after ** must be a mapping, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4r/pj221_cx4fsc736mmyv_9lnr0000gn/T/ipykernel_1417/853633943.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m roc_aucs, preds = cv_inner_loop(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLGBMClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mhyper_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyper_parameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mall_breaks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_breaks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/4r/pj221_cx4fsc736mmyv_9lnr0000gn/T/ipykernel_1417/2545322615.py\u001b[0m in \u001b[0;36mcv_inner_loop\u001b[0;34m(clf, hyper_parameters, all_breaks, X_train, y_train, sample_size)\u001b[0m\n\u001b[1;32m     50\u001b[0m             \u001b[0;31m# breaks = hp_.pop(\"breaks\")\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mhp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m             \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: lightgbm.sklearn.LGBMModel.set_params() argument after ** must be a mapping, not str"
     ]
    }
   ],
   "source": [
    "roc_aucs, preds = cv_inner_loop(\n",
    "    clf = LGBMClassifier(),\n",
    "    hyper_parameters = hyper_parameters,\n",
    "    all_breaks = all_breaks,\n",
    "    X_train = X_train,\n",
    "    y_train = y_train, \n",
    "    sample_size = 0.0001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0a80c21c-1b25-455f-9923-49ec8eb66fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm1 = dict(\n",
    "    clf=LGBMClassifier(),\n",
    "    hp=dict(\n",
    "        max_depth=[5]\n",
    "    )\n",
    ")\n",
    "lgbm2 = dict(\n",
    "    clf=LGBMClassifier(),\n",
    "    hp=dict(\n",
    "        max_depth=[100, 200]\n",
    "    )\n",
    ")\n",
    "clfs = dict(\n",
    "    lgbm1=lgbm1,\n",
    "    lgbm2=lgbm2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "0805aec6-6eb2-4bb5-a9e1-c1c39e515eed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lgbm1': {'clf': LGBMClassifier(), 'hp': {'max_depth': [5]}},\n",
       " 'lgbm2': {'clf': LGBMClassifier(), 'hp': {'max_depth': [100, 200]}}}"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ae987a82-9b5c-4f24-b353-d766698f41bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for LGBMClassifier()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6bc4803705f418ca4454acecd633ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48f3d562be724d85b7afbe6e577f585b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4r/pj221_cx4fsc736mmyv_9lnr0000gn/T/ipykernel_1417/147852572.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m clfs, meta_clf = ensemble_learning(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mbase_clfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclfs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmeta_clf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLGBMClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mall_breaks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_breaks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/4r/pj221_cx4fsc736mmyv_9lnr0000gn/T/ipykernel_1417/2525767045.py\u001b[0m in \u001b[0;36mensemble_learning\u001b[0;34m(base_clfs, meta_clf, X_train, y_train, use_meta_features, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0;31m## Fit each classifier to the predicted probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mclfk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclf_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "clfs, meta_clf = ensemble_learning(\n",
    "    base_clfs=clfs,\n",
    "    meta_clf=LGBMClassifier(),\n",
    "    all_breaks=all_breaks,\n",
    "    X_train=X_train, \n",
    "    y_pred_prob_train=y_pred_prob_train,\n",
    "    y_train = y_train,\n",
    "    sample_size=0.0001\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
