{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c9d9d89-4af7-4dc8-b1f3-c77dddad0c36",
   "metadata": {},
   "source": [
    "# Model training and prediction - `s30d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f08843e3-1ca8-42ec-a344-1c5f560441dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4918d091-6dc7-47e1-8419-8973ebbf246c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ludvigwarnberggerdin/projects/ttris/pemett'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66d758ca-f517-4df4-8bc0-f1cbc91226ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb6ed398-04d7-4bba-8693-e79e973e5487",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"./data/processed/s30d/X_train.csv\", index_col = 0)\n",
    "y_train = pd.read_csv(\"./data/processed/s30d/y_train.csv\", index_col = 0).s30d\n",
    "X_test = pd.read_csv(\"./data/processed/s30d/X_test.csv\", index_col = 0)\n",
    "y_test = pd.read_csv(\"./data/processed/s30d/y_test.csv\", index_col = 0).s30d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb610948-9c80-4507-861c-feeb3318fbb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    94.197074\n",
       "1.0     5.802926\n",
       "Name: s30d, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts() / len(y_train.index) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe14dc61-2fe7-4188-9b39-5c4abb2f149d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_features = [\"age\", \"hr\", \"sbp\", \"dbp\", \"spo2\", \"rr\", \"delay\"]\n",
    "cat_features = list(X_train.loc[:, ~X_train.columns.isin(cont_features)].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00463518-a24f-466b-93db-529f65cf8a96",
   "metadata": {},
   "source": [
    "### Lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "084141d7-22d5-435b-b284-8e8eb769ced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b17e6786-1b75-4f11-a8d8-05cbe6d3e68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "continous_transformer = StandardScaler()\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cont', continous_transformer, cont_features)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdb528c2-95b8-4505-801c-9fddf7a94935",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train.loc[:, cont_features] = ss.fit_transform(X_train.loc[:, cont_features])\n",
    "X_test.loc[:, cont_features] = ss.fit_transform(X_test.loc[:, cont_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db9aca14-cc6c-49eb-8d39-6604121d1c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc7a154a-48d9-4936-bf5a-b6695a639991",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ludvigwarnberggerdin/miniforge3/envs/pemett/lib/python3.10/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    categorical_feature = cat_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc1c960e-bbf2-4279-853c-f3d4207a7ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob_train = clf.predict_proba(X = X_train)\n",
    "y_pred_prob_test = clf.predict_proba(X = X_test)\n",
    "y_pred_train = clf.predict(X = X_train)\n",
    "y_pred_test = clf.predict(X = X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ee16dc-8458-444d-b014-bc6852a5dfcd",
   "metadata": {},
   "source": [
    "Report for continous scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c592bf4a-44bf-40c5-a850-662b79c29caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      5860\n",
      "         1.0       1.00      0.99      1.00       361\n",
      "\n",
      "    accuracy                           1.00      6221\n",
      "   macro avg       1.00      1.00      1.00      6221\n",
      "weighted avg       1.00      1.00      1.00      6221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true = y_train, y_pred = y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "740c9e4e-0d5f-416e-9fb9-0a947c589c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.98      1954\n",
      "         1.0       0.77      0.62      0.69       120\n",
      "\n",
      "    accuracy                           0.97      2074\n",
      "   macro avg       0.87      0.80      0.83      2074\n",
      "weighted avg       0.96      0.97      0.97      2074\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true = y_test, y_pred = y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205b5800-760b-4d9b-8b96-c7ea65b7d47a",
   "metadata": {},
   "source": [
    "Gridsearch breaks for the continous score (to enable comparison with clinicians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f7e57514-909f-4bdb-83e4-6f83e4e7e423",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "from src.models.train_model import generate_all_combinations\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from typing import Callable, Optional\n",
    "\n",
    "from sklearn.model_selection import cross_val_predict, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "d5af0873-c6fb-4b4d-9714-987c8bb04315",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_inner_loop(base_clfs: list, hyper_parameters: dict,\n",
    "                  inner_loop: Callable, \n",
    "                  X: pd.DataFrame, \n",
    "                  y: pd.Series) -> np.ndarray:\n",
    "    \"\"\"Run inner loop of k-fold cross-validation.\n",
    "    \n",
    "    Uses sklearn's cross_val_predict.\n",
    "    \n",
    "    That is,\n",
    "    1. Fit classifier to the training folds.\n",
    "    2. Make prediction on the validation fold.\n",
    "    3. Use all folds as validation fold, one time each.\n",
    "\n",
    "    Args:\n",
    "      base_clfs: List of classifiers. E.g. [LGBMClassifier, LogisticRegression]\n",
    "      inner_loop: scikit-learn callable to split into folds\n",
    "      X: Features\n",
    "      y: Targets\n",
    "\n",
    "    Returns:\n",
    "      Each column represent predictions by each respective classifier\n",
    "    \"\"\"\n",
    "    predictions = np.zeros((len(X_train.index), ))\n",
    "    for clfk in base_clfs.keys(): \n",
    "        ks = [s for s in hyper_parameters.keys() if clfk in s]\n",
    "        clf_params = {k.split(\"__\")[1]: hyper_parameters.get(k) for k in ks}\n",
    "        clf = base_clfs[clfk]\n",
    "        clf.set_params(**clf_params)\n",
    "        print(\"Running predictions for \" + str(clf) + \" with params \" +  str(clf_params))\n",
    "        preds = cross_val_predict(\n",
    "            estimator=clf,\n",
    "            X=X,\n",
    "            y=y,\n",
    "            cv=inner_loop\n",
    "        )\n",
    "        if predictions.any():\n",
    "            predictions = np.hstack([predictions, preds[:, np.newaxis]])\n",
    "        else:\n",
    "            predictions = preds[:, np.newaxis]\n",
    "\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "104baafa-9465-4074-b79c-a6f2c44b8906",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cv_outer_loop(base_clfs: list, meta_clf: Callable,\n",
    "                  all_hyper_parameters: list,\n",
    "                  X: pd.DataFrame, y: pd.Series,\n",
    "                  use_meta_features: bool = False, \n",
    "                  **kwargs):\n",
    "    \"\"\"Conduct outer cross-validation.\n",
    "    \n",
    "    That is, find the best combination cut-points for the classifier.\n",
    "    \n",
    "    Inspired by:\n",
    "        https://github.com/rasbt/mlxtend/blob/master/mlxtend/classifier/stacking_cv_classification.py\n",
    "        \n",
    "    Args:\n",
    "        base_clfs: Base classifiers.\n",
    "        meta_clf:\n",
    "        X_train:\n",
    "        y_train\n",
    "        use_meta_features\n",
    "    \"\"\"\n",
    "    ## Setup splitting\n",
    "    inner_folds = 5\n",
    "    outer_folds = 2\n",
    "    inner_loop = StratifiedKFold(n_splits = inner_folds)\n",
    "    outer_loop = StratifiedKFold(n_splits = outer_folds)\n",
    "    \n",
    "    ## Setup for recording auc from each combination of hps\n",
    "    roc_aucs = pd.DataFrame(\n",
    "        data = np.zeros((len(all_hyper_parameters), outer_folds)),\n",
    "        columns = range(1, outer_folds + 1),\n",
    "        index = [str(hp) for hp in all_hyper_parameters]\n",
    "    )\n",
    "    \n",
    "    for i, hyper_parameters in enumerate(all_hyper_parameters):\n",
    "        \n",
    "        breaks = hyper_parameters.pop(\"breaks\")\n",
    "\n",
    "        for j, (train_index, val_index) in enumerate(outer_loop.split(X, y)):\n",
    "        \n",
    "            X_train = X.iloc[train_index]\n",
    "            y_train = y.iloc[train_index]\n",
    "            X_val = X.iloc[val_index]\n",
    "            y_val = y.iloc[val_index]\n",
    "        \n",
    "            inner_predictions = cv_inner_loop(\n",
    "                base_clfs=base_clfs,\n",
    "                hyper_parameters=hyper_parameters,\n",
    "                inner_loop=inner_loop,\n",
    "                X=X_train,\n",
    "                y=y_train\n",
    "            )\n",
    "            \n",
    "            if use_meta_features: pass\n",
    "            \n",
    "            # Fit meta classifier to base predictions\n",
    "            meta_clf.fit(inner_predictions, y_train)\n",
    "            print(X_val)\n",
    "            y_pred_prob_meta = meta_clf.predict_proba(X_val)\n",
    "            binned_predictions = pd.cut(\n",
    "                x=y_pred_prob_meta[:, 1],\n",
    "                bins=breaks,\n",
    "                labels=[0, 1, 2, 3],\n",
    "                right=True,\n",
    "                include_lowest=False\n",
    "            )\n",
    "            roc_aucs.iloc[j, i] = roc_auc_score(\n",
    "                y_true=y_val,\n",
    "                y_score=binned_predictions\n",
    "            )\n",
    "\n",
    "    return base_clfs, meta_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "5ee3654e-7a80-4e7d-be40-7dfec004e221",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "all_breaks = [(0, ) + x + (np.inf,) for x in it.combinations(np.arange(0.01, 1, 0.01), r=3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "8bff7851-5b1f-4d4c-b729-272b7c698886",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_parameters = {\n",
    "    \"lgbm1__max_depth\": [100, 500],\n",
    "    \"lgbm1__num_leaves\": [200, 100],\n",
    "    \"lgbm2__max_depth\": [100, 200],\n",
    "    \"breaks\": all_breaks[:5]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "27ae05c0-1ad4-4b86-8a15-b78d89c21982",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_clfs = {\n",
    "    \"lgbm1\": LGBMClassifier(),\n",
    "    \"lgbm2\": LGBMClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "8e3662ba-f282-4633-af9a-9352ec551ed8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_hyper_parameters = generate_all_combinations(hyper_parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "1d1a2ca9-96d1-4f79-b38c-e7448d06a6a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'lgbm1__max_depth': 100, 'lgbm1__num_leaves': 200, 'lgbm2__max_depth': 100, 'breaks': (0, 0.01, 0.02, 0.03, inf)}\n",
      "Running predictions for LGBMClassifier(max_depth=100, num_leaves=200) with params {'max_depth': 100, 'num_leaves': 200}\n",
      "Running predictions for LGBMClassifier(max_depth=100) with params {'max_depth': 100}\n",
      "            age  moi  sex  mot  tran  egcs  mgcs  vgcs  avpu        hr  \\\n",
      "259   -0.665919    0    1    2     0     3     5     4     3  0.034803   \n",
      "11083  0.068646    0    1    2     0     3     5     4     3  0.351697   \n",
      "2865   0.068646    0    0    0     1     3     5     4     3  1.682654   \n",
      "4378  -1.133369    7    1    0     1     3     5     4     3 -0.408849   \n",
      "5060  -0.732697    0    0    2     0     3     5     4     3  1.999548   \n",
      "...         ...  ...  ...  ...   ...   ...   ...   ...   ...       ...   \n",
      "3644   0.402540    3    0    2     0     3     5     4     3 -0.282092   \n",
      "7604  -1.200148    5    1    2     0     3     5     4     3 -0.472228   \n",
      "3785   0.068646    7    0    2     1     3     5     4     3 -0.282092   \n",
      "4827  -0.332025    5    1    2     0     3     5     4     3  0.098182   \n",
      "1875   1.270662    7    1    0     1     3     5     4     3 -0.091955   \n",
      "\n",
      "            sbp       dbp      spo2        rr     delay  \n",
      "259   -0.125211  0.250263  0.494443 -0.503873 -0.058664  \n",
      "11083 -1.020551 -0.202994  0.494443  0.658768 -0.058664  \n",
      "2865   0.490336  1.156779 -0.147543  1.821409  0.117150  \n",
      "4378   0.546295  0.099178  0.173450 -1.085194 -0.003734  \n",
      "5060   0.154583 -0.051908 -0.147543 -1.085194 -0.058664  \n",
      "...         ...       ...       ...       ...       ...  \n",
      "3644   0.378419  0.174720 -0.147543 -0.503873 -0.058664  \n",
      "7604  -0.349046 -0.051908  0.494443 -1.085194 -0.058664  \n",
      "3785   2.057183  3.649697 -0.147543 -0.503873 -0.058664  \n",
      "4827   0.210542  1.383408  0.173450  0.077447 -0.058664  \n",
      "1875   0.434377 -1.033967  0.173450 -1.085194  7.554992  \n",
      "\n",
      "[3111 rows x 15 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ludvigwarnberggerdin/miniforge3/envs/pemett/lib/python3.10/site-packages/sklearn/base.py:438: UserWarning: X has feature names, but LogisticRegression was fitted without feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4r/pj221_cx4fsc736mmyv_9lnr0000gn/T/ipykernel_1805/4156718554.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m a, b = cv_outer_loop(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mbase_clfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbase_clfs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmeta_clf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLogisticRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mall_hyper_parameters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_hyper_parameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mall_breaks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_breaks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/4r/pj221_cx4fsc736mmyv_9lnr0000gn/T/ipykernel_1805/3968137771.py\u001b[0m in \u001b[0;36mcv_outer_loop\u001b[0;34m(base_clfs, meta_clf, all_hyper_parameters, X, y, use_meta_features, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mmeta_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minner_predictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0my_pred_prob_meta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeta_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             binned_predictions = pd.cut(\n\u001b[1;32m     60\u001b[0m                 \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_pred_prob_meta\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/pemett/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1668\u001b[0m         )\n\u001b[1;32m   1669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0movr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1670\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict_proba_lr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1671\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1672\u001b[0m             \u001b[0mdecision\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/pemett/lib/python3.10/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36m_predict_proba_lr\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0mmulticlass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mhandled\u001b[0m \u001b[0mby\u001b[0m \u001b[0mnormalizing\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mover\u001b[0m \u001b[0mall\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m         \"\"\"\n\u001b[0;32m--> 439\u001b[0;31m         \u001b[0mprob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m         \u001b[0mexpit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/pemett/lib/python3.10/site-packages/sklearn/linear_model/_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    405\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/pemett/lib/python3.10/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 561\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    562\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/pemett/lib/python3.10/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    790\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 792\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"allow-nan\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/pemett/lib/python3.10/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    112\u001b[0m         ):\n\u001b[1;32m    113\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"infinity\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"NaN, infinity\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    115\u001b[0m                 msg_err.format(\n\u001b[1;32m    116\u001b[0m                     \u001b[0mtype_err\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "a, b = cv_outer_loop(\n",
    "    base_clfs=base_clfs,\n",
    "    meta_clf=LogisticRegression(),\n",
    "    all_hyper_parameters=all_hyper_parameters,\n",
    "    all_breaks=all_breaks,\n",
    "    X=X_train,\n",
    "    y=y_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ae987a82-9b5c-4f24-b353-d766698f41bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for LGBMClassifier()\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6bc4803705f418ca4454acecd633ec6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48f3d562be724d85b7afbe6e577f585b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "tuple indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4r/pj221_cx4fsc736mmyv_9lnr0000gn/T/ipykernel_1417/147852572.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m clfs, meta_clf = ensemble_learning(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mbase_clfs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclfs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mmeta_clf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mLGBMClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mall_breaks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mall_breaks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/4r/pj221_cx4fsc736mmyv_9lnr0000gn/T/ipykernel_1417/2525767045.py\u001b[0m in \u001b[0;36mensemble_learning\u001b[0;34m(base_clfs, meta_clf, X_train, y_train, use_meta_features, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m     \u001b[0;31m## Fit each classifier to the predicted probabilities\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mclfk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclf_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: tuple indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "clfs, meta_clf = ensemble_learning(\n",
    "    base_clfs=clfs,\n",
    "    meta_clf=LGBMClassifier(),\n",
    "    all_breaks=all_breaks,\n",
    "    X_train=X_train, \n",
    "    y_pred_prob_train=y_pred_prob_train,\n",
    "    y_train = y_train,\n",
    "    sample_size=0.0001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "39e77566-7219-4f00-8a2a-5a4a20be9d71",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2054303279.py, line 45)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"/var/folders/4r/pj221_cx4fsc736mmyv_9lnr0000gn/T/ipykernel_6798/2054303279.py\"\u001b[0;36m, line \u001b[0;32m45\u001b[0m\n\u001b[0;31m    hp =\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def cv_outer_loop(base_clfs: list, meta_clf: Callable,\n",
    "                  X_train: pd.DataFrame, y_train: pd.Series,\n",
    "                  use_meta_features: bool = False, \n",
    "                  **kwargs):\n",
    "    \"\"\"Conduct outer cross-validation.\n",
    "    \n",
    "    That is, find the best combination cut-points for the classifier.\n",
    "    \n",
    "    Inspired by:\n",
    "        https://github.com/rasbt/mlxtend/blob/master/mlxtend/classifier/stacking_cv_classification.py\n",
    "        \n",
    "    Args:\n",
    "        base_clfs: Base classifiers.\n",
    "        meta_clf:\n",
    "        X_train:\n",
    "        y_train\n",
    "        use_meta_features\n",
    "    \"\"\"\n",
    "    ## Fit each classifier to the original training set\n",
    "    meta_predictions = np.array([])\n",
    "    clf_keys = base_clfs.keys()\n",
    "    ## Setup splitting\n",
    "    inner_folds = 5\n",
    "    outer_folds = 2\n",
    "    inner_loop = StratifiedKFold(n_splits = inner_folds)\n",
    "    outer_loop = StratifiedKFold(n_splits = outer_folds)\n",
    "    \n",
    "    ## Setup for recording auc from each combination of hps\n",
    "    roc_aucs = pd.DataFrame(\n",
    "        data = np.zeros((len(hyper_parameters), n_folds)),\n",
    "        columns = range(1, n_folds + 1),\n",
    "        index = [str(hp) for hp in hyper_parameters]\n",
    "    )\n",
    "\n",
    "    for i, (train_index, val_index) in enumerate(outer_loop.split(X_train, y_train)):\n",
    "        \n",
    "        X_train_ = X_train.iloc[train_index]\n",
    "        y_train_ = y_train.iloc[train_index]\n",
    "\n",
    "        X_val = X_train.iloc[val_index]\n",
    "        y_val = y_train.iloc[val_index]\n",
    "        \n",
    "        inner_predictions = cv_inner_loop(\n",
    "            base_clfs = base_clfs,\n",
    "            \n",
    "        )\n",
    "        \n",
    "        for j, hp in enumerate(hyper_parameters):\n",
    "            \n",
    "            hp = \n",
    "            breaks = hp['breaks']\n",
    "            \n",
    "            ## Fit each classifier to the predicted probabilities\n",
    "            base_predictions = inner_loop(\n",
    "                base_clfs=base_clfs\n",
    "                hyper_parameters=hyper_parameters,\n",
    "                inner_loop=inner_loop,\n",
    "                X=X_train_,\n",
    "                y=y_train_\n",
    "            )\n",
    "    \n",
    "            ## Fit the meta clf to predictions, and predict on validation set\n",
    "            meta_clf.fit(predictions, y_train)\n",
    "            y_pred_prob_meta = meta_clf.predict_proba(predictions)\n",
    "            binned_predictions = pd.cut(y_pred_prob_val[:, 1], breaks, labels = [0, 1, 2, 3], right = True, include_lowest = False)\n",
    "            roc_aucs.iloc[j, i] = roc_auc_score(y_true = y_val, y_score = binned_predictions)\n",
    "    \n",
    "    return base_clfs, meta_clf"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
