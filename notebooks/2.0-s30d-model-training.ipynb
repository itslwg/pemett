{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c9d9d89-4af7-4dc8-b1f3-c77dddad0c36",
   "metadata": {},
   "source": [
    "# Model training and prediction - `s30d`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f08843e3-1ca8-42ec-a344-1c5f560441dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4918d091-6dc7-47e1-8419-8973ebbf246c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/ludvigwarnberggerdin/projects/python/pemett'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66d758ca-f517-4df4-8bc0-f1cbc91226ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import StackingClassifier, RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb6ed398-04d7-4bba-8693-e79e973e5487",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv(\"./data/processed/s30d/X_train.csv\", index_col = 0)\n",
    "y_train = pd.read_csv(\"./data/processed/s30d/y_train.csv\", index_col = 0).s30d\n",
    "X_test = pd.read_csv(\"./data/processed/s30d/X_test.csv\", index_col = 0)\n",
    "y_test = pd.read_csv(\"./data/processed/s30d/y_test.csv\", index_col = 0).s30d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb610948-9c80-4507-861c-feeb3318fbb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0    94.197074\n",
       "1.0     5.802926\n",
       "Name: s30d, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts() / len(y_train.index) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe14dc61-2fe7-4188-9b39-5c4abb2f149d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cont_features = [\"age\", \"hr\", \"sbp\", \"dbp\", \"spo2\", \"rr\", \"delay\"]\n",
    "cat_features = list(X_train.loc[:, ~X_train.columns.isin(cont_features)].columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00463518-a24f-466b-93db-529f65cf8a96",
   "metadata": {},
   "source": [
    "### Lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "084141d7-22d5-435b-b284-8e8eb769ced3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b17e6786-1b75-4f11-a8d8-05cbe6d3e68e",
   "metadata": {},
   "outputs": [],
   "source": [
    "continous_transformer = StandardScaler()\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cont', continous_transformer, cont_features)]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdb528c2-95b8-4505-801c-9fddf7a94935",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X_train.loc[:, cont_features] = ss.fit_transform(X_train.loc[:, cont_features])\n",
    "X_test.loc[:, cont_features] = ss.fit_transform(X_test.loc[:, cont_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db9aca14-cc6c-49eb-8d39-6604121d1c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = LGBMClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc7a154a-48d9-4936-bf5a-b6695a639991",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ludvigwarnberggerdin/miniforge3/envs/pemett/lib/python3.10/site-packages/lightgbm/basic.py:2065: UserWarning: Using categorical_feature in Dataset.\n",
      "  _log_warning('Using categorical_feature in Dataset.')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LGBMClassifier()"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.fit(\n",
    "    X = X_train,\n",
    "    y = y_train,\n",
    "    categorical_feature = cat_features\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc1c960e-bbf2-4279-853c-f3d4207a7ab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_prob_train = clf.predict_proba(X = X_train)\n",
    "y_pred_prob_test = clf.predict_proba(X = X_test)\n",
    "y_pred_train = clf.predict(X = X_train)\n",
    "y_pred_test = clf.predict(X = X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3ee16dc-8458-444d-b014-bc6852a5dfcd",
   "metadata": {},
   "source": [
    "Report for continous scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c592bf4a-44bf-40c5-a850-662b79c29caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00      5860\n",
      "         1.0       1.00      0.99      1.00       361\n",
      "\n",
      "    accuracy                           1.00      6221\n",
      "   macro avg       1.00      1.00      1.00      6221\n",
      "weighted avg       1.00      1.00      1.00      6221\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true = y_train, y_pred = y_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "740c9e4e-0d5f-416e-9fb9-0a947c589c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.99      0.98      1954\n",
      "         1.0       0.77      0.62      0.69       120\n",
      "\n",
      "    accuracy                           0.97      2074\n",
      "   macro avg       0.87      0.80      0.83      2074\n",
      "weighted avg       0.96      0.97      0.97      2074\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_true = y_test, y_pred = y_pred_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205b5800-760b-4d9b-8b96-c7ea65b7d47a",
   "metadata": {},
   "source": [
    "Gridsearch breaks for the continous score (to enable comparison with clinicians)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "ad8809c8-cbe9-400f-90ce-6ebfb1a88f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import random\n",
    "from src.models.train_model import generate_all_combinations\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "def gridsearch_breaks(clf, hyper_parameters, all_breaks,\n",
    "                      X_train, y_pred_prob_train, y_train, \n",
    "                      sample_size = None) -> tuple([tuple, list, pd.DataFrame]):\n",
    "    \"\"\"Gridsearch breaks for continous probabilites.\n",
    "    \n",
    "    Breaks are chosen based on validation set performance.\n",
    "    \"\"\"\n",
    "    ## Sample combinations\n",
    "    if sample_size:\n",
    "        all_breaks = random.sample(all_breaks, round(sample_size * len(all_breaks)))\n",
    "        \n",
    "    ## Merge breaks and model hyper parameters\n",
    "    d = {**hyper_parameters, 'breaks': all_breaks}\n",
    "    hyper_parameters = generate_all_combinations(d)\n",
    "    \n",
    "    ## Compute predictions and perofmrance of each combination over five folds\n",
    "    n_folds = 2\n",
    "    preds = np.zeros((len(X_train.index), ))\n",
    "    roc_aucs = pd.DataFrame(\n",
    "        data = np.zeros((len(hyper_parameters), n_folds)),\n",
    "        columns = range(1, n_folds + 1),\n",
    "        index = [str(hp) for hp in hyper_parameters]\n",
    "    )\n",
    "\n",
    "    for i, (train_index, val_index) in enumerate(StratifiedKFold(n_splits = n_folds).split(X_train, y_train)):\n",
    "\n",
    "        X_train_ = X_train.iloc[train_index]\n",
    "        y_train_ = y_train.iloc[train_index]\n",
    "\n",
    "        X_val = X_train.iloc[val_index]\n",
    "        y_val = y_train.iloc[val_index]\n",
    "\n",
    "        for j, hp in enumerate(tqdm(hyper_parameters)):\n",
    "\n",
    "            hp_ = copy.deepcopy(hp)\n",
    "            breaks = hp_.pop(\"breaks\")\n",
    "\n",
    "            clf = clf.set_params(**hp_)\n",
    "            clf.fit(X_train_, y_train_)\n",
    "\n",
    "            y_pred_val = clf.predict(X_val)\n",
    "            y_pred_prob_val = clf.predict_proba(X_val)\n",
    "            preds[val_index] = y_pred_prob_val[:, 1]\n",
    "\n",
    "            binned_predictions = pd.cut(y_pred_prob_val[:, 1], breaks, labels = [0, 1, 2, 3], right = True, include_lowest = False)\n",
    "            roc_aucs.iloc[j, i] = roc_auc_score(y_true = y_val, y_score = binned_predictions)\n",
    "\n",
    "    return roc_aucs.mean(axis = 1), preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "19f4161c-d968-469d-b640-2d16cc0671d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "all_breaks = [(0, ) + x + (np.inf,) for x in it.combinations(np.arange(0.01, 1, 0.01), r=3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "263a6b02-bc27-4de9-8177-c15b856ecf3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyper_parameters = {'max_depth': [5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "1d1a2ca9-96d1-4f79-b38c-e7448d06a6a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a130fd4445847c1a91da6072815d593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12b10347ac9e4907b25574d9eafc8a74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "roc_aucs, preds = gridsearch_breaks(\n",
    "    clf = LGBMClassifier(),\n",
    "    hyper_parameters = hyper_parameters,\n",
    "    all_breaks = all_breaks,\n",
    "    X_train = X_train,\n",
    "    y_pred_prob_train = y_pred_prob_train[:, 1], ## Predicted probabilities of 1s, i.e. dead within 30 days\n",
    "    y_train = y_train, \n",
    "    sample_size = 0.0001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "f7d5524f-bd2e-418b-b1ce-7bd62096ed49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "from sklearn.base import ClassifierMixin\n",
    "\n",
    "\n",
    "class _BaseStackingClassifier(ClassifierMixin):\n",
    "    \"\"\"Base class of stacking classifiers\n",
    "    \"\"\"\n",
    "\n",
    "    def _do_predict(self, X, predict_fn):\n",
    "        meta_features = self.predict_meta_features(X)\n",
    "\n",
    "        if not self.use_features_in_secondary:\n",
    "            return predict_fn(meta_features)\n",
    "        elif sparse.issparse(X):\n",
    "            return predict_fn(sparse.hstack((X, meta_features)))\n",
    "        else:\n",
    "            return predict_fn(np.hstack((X, meta_features)))\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\" Predict target values for X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : numpy array, shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        labels : array-like, shape = [n_samples]\n",
    "            Predicted class labels.\n",
    "\n",
    "        \"\"\"\n",
    "        return self._do_predict(X, self.meta_clf_.predict)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        \"\"\" Predict class probabilities for X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        proba : array-like, shape = [n_samples, n_classes] or a list of \\\n",
    "                n_outputs of such arrays if n_outputs > 1.\n",
    "            Probability for each class per sample.\n",
    "\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, ['clfs_', 'meta_clf_'])\n",
    "\n",
    "        return self._do_predict(X, self.meta_clf_.predict_proba)\n",
    "\n",
    "    def decision_function(self, X):\n",
    "        \"\"\" Predict class confidence scores for X.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : {array-like, sparse matrix}, shape = [n_samples, n_features]\n",
    "            Training vectors, where n_samples is the number of samples and\n",
    "            n_features is the number of features.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        scores : shape=(n_samples,) if n_classes == 2 else \\\n",
    "            (n_samples, n_classes).\n",
    "            Confidence scores per (sample, class) combination. In the binary\n",
    "            case, confidence score for self.classes_[1] where >0 means this\n",
    "            class would be predicted.\n",
    "\n",
    "        \"\"\"\n",
    "        check_is_fitted(self, ['clfs_', 'meta_clf_'])\n",
    "\n",
    "        return self._do_predict(X, self.meta_clf_.decision_function)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db4b25fb-9a57-43e2-9d1b-14f31ff1bc40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def StackingClassifier(_BaseStackingClassifier):\n",
    "    \n",
    "    def __init__(self, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "39e77566-7219-4f00-8a2a-5a4a20be9d71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_learning(base_clfs, meta_clf, y_train, **kwargs):\n",
    "    \"\"\"Conduct ensemble learning.\n",
    "    \n",
    "    Inspired by:\n",
    "        https://github.com/rasbt/mlxtend/blob/master/mlxtend/classifier/stacking_cv_classification.py\n",
    "    \"\"\"\n",
    "    ## Fit each classifier to the original training set\n",
    "    predictions = np.array([])\n",
    "    clf_keys = base_clfs.keys()\n",
    "    ## Get predicted probabilities on the training set for each classifier\n",
    "    for clfk in clf_keys:\n",
    "        d = clfs[clfk]\n",
    "        clf = d['clf']\n",
    "        hp = d['hp']\n",
    "        print(\"Running predictions for \" + str(clf))\n",
    "        roc_aucs, preds = gridsearch_breaks(\n",
    "            clf = clf,\n",
    "            hyper_parameters = hp,\n",
    "            y_train=y_train,\n",
    "            **kwargs\n",
    "        )\n",
    "        if predictions.any():\n",
    "            predictions = np.hstack([predictions, preds[:, np.newaxis]])\n",
    "        else:\n",
    "            predictions = preds[:, np.newaxis]\n",
    "\n",
    "    ## Fit each classifier to the predicted probabilities\n",
    "    for clfk in clf_keys:\n",
    "        d = base_clfs[clfk]\n",
    "        clf = d['clf']\n",
    "        hp = d['hp']\n",
    "        \n",
    "        clf.fit(\n",
    "            X=predictions, \n",
    "            y=y_train\n",
    "        )\n",
    "    ## Fit the meta classifier\n",
    "    meta_clf.fit(predictions, y_train)\n",
    "    \n",
    "    return base_clfs, meta_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "f008eef4-35ed-4718-b60c-bff6727a6865",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "0a80c21c-1b25-455f-9923-49ec8eb66fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm = dict(\n",
    "    clf=LGBMClassifier(),\n",
    "    hp=dict(\n",
    "        max_depth=[5]\n",
    "    )\n",
    ")\n",
    "lr = dict(\n",
    "    clf=LGBMClassifier(),\n",
    "    hp=dict(\n",
    "        max_depth=[100, 200]\n",
    "    )\n",
    ")\n",
    "clfs = dict(\n",
    "    lgbm=lgbm,\n",
    "    lr=lr\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "ae987a82-9b5c-4f24-b353-d766698f41bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for LGBMClassifier(max_depth=5)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee579fe6db76475c866756fc48116ed4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8aa5b690373c4da7bd6dec63f138e9cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running predictions for LGBMClassifier(max_depth=200)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "11f1c8c215d942f39965c1c599b62431",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bda17f07eb2a41cc8a7edb950738700f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "clfs, meta_clf = ensemble_learning(\n",
    "    base_clfs=clfs,\n",
    "    meta_clf=LGBMClassifier(),\n",
    "    all_breaks=all_breaks,\n",
    "    X_train=X_train, \n",
    "    y_pred_prob_train=y_pred_prob_train,\n",
    "    y_train = y_train,\n",
    "    sample_size=0.0001\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "05500090-389a-481d-aedd-5a3c8d1a1441",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Number of features of the model must match the input. Model n_features_ is 2 and input n_features is 15",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/4r/pj221_cx4fsc736mmyv_9lnr0000gn/T/ipykernel_1663/2807308541.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmeta_clf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniforge3/envs/pemett/lib/python3.10/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[1;32m    982\u001b[0m                 pred_leaf=False, pred_contrib=False, **kwargs):\n\u001b[1;32m    983\u001b[0m         \u001b[0;34m\"\"\"Docstring is inherited from the LGBMModel.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 984\u001b[0;31m         result = self.predict_proba(X, raw_score, start_iteration, num_iteration,\n\u001b[0m\u001b[1;32m    985\u001b[0m                                     pred_leaf, pred_contrib, **kwargs)\n\u001b[1;32m    986\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_objective\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mraw_score\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpred_leaf\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniforge3/envs/pemett/lib/python3.10/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[1;32m    995\u001b[0m                       pred_leaf=False, pred_contrib=False, **kwargs):\n\u001b[1;32m    996\u001b[0m         \u001b[0;34m\"\"\"Docstring is set after definition, using a template.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 997\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    998\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_objective\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mraw_score\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpred_leaf\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    999\u001b[0m             _log_warning(\"Cannot compute class probabilities or labels \"\n",
      "\u001b[0;32m~/miniforge3/envs/pemett/lib/python3.10/site-packages/lightgbm/sklearn.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, **kwargs)\u001b[0m\n\u001b[1;32m    798\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    799\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 800\u001b[0;31m             raise ValueError(\"Number of features of the model must \"\n\u001b[0m\u001b[1;32m    801\u001b[0m                              \u001b[0;34mf\"match the input. Model n_features_ is {self._n_features} and \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    802\u001b[0m                              f\"input n_features is {n_features}\")\n",
      "\u001b[0;31mValueError\u001b[0m: Number of features of the model must match the input. Model n_features_ is 2 and input n_features is 15"
     ]
    }
   ],
   "source": [
    "meta_clf.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
